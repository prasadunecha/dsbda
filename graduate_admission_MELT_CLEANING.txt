import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt



df = pd.read_csv('Admission_Predict.csv')
df.head()



//1. Check for duplicate rows and remove it
duplicate_rows = df.duplicated()
print("Number of duplicate rows:", duplicate_rows.sum())

# Remove duplicate rows
df = df.drop_duplicates()



//2. Plot heat map for the continuous data.

# Select continuous columns for the heatmap
continuous_columns = ['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit ']

# Create a correlation matrix
correlation_matrix = df[continuous_columns].corr()

# Plot the heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()





//3. Check for null/Nan values and replace them with appropriate values:
# Check for null values
null_values = df.isnull().sum()
print("Null values:\n", null_values)

# Replace null values with appropriate values (e.g., mean, median, etc.)
df = df.fillna(df.mean())






//4. Consider the column with the highest correlation in the dataset to build a linear regression model to predict the chance of admission:

from sklearn.linear_model import LinearRegression

# Select the column with the highest correlation (e.g., CGPA in this example)
feature_column = 'CGPA'

# Prepare the data for linear regression
X = df[[feature_column]]
y = df['Chance of Admit ']

# Build the linear regression model
model = LinearRegression()
model.fit(X, y)

# Make predictions
predicted_chance_of_admit = model.predict(X)



5. Create data subsets by making classes for the chance of admission:
# Define the class intervals
class_intervals = [0, 0.5, 0.75, 1]

# Create the classes for chance of admission
df['Admission Class'] = pd.cut(df['Chance of Admit '], bins=class_intervals, labels=['Not Admitted', 'Might Get Admitted', '




6. Merge two subsets:
# merged_df = pd.concat([df1, df2], axis=0)




7. Sort data using GRE, TOEFL, and University rating:
sorted_df = df.sort_values(by=['GRE Score', 'TOEFL Score', 'University Rating'])
sorted_df.head()



8. Transpose the data:
transposed_df = df.transpose()
transposed_df.head()



9. Melting data to long format:
melted_df = pd.melt(df, id_vars=['Serial No.'], value_vars=['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit '], var_name='Variable', value_name='Value')
melted_df.head()




10. Casting data to wide format:
wide_df = melted_df.pivot(index='Serial No.', columns='Variable', values='Value')
wide_df.head()
